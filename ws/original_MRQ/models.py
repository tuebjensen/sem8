# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.

# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.


from collections.abc import Callable
from functools import partial

import torch
import torch.nn as nn
import torch.nn.functional as F


def weight_init(layer: torch.nn.modules):
    if isinstance(layer, (nn.Linear, nn.Conv2d)):
        gain = nn.init.calculate_gain("relu")
        nn.init.xavier_uniform_(layer.weight.data, gain)
        if hasattr(layer.bias, "data"):
            layer.bias.data.fill_(0.0)


def ln_activ(x: torch.Tensor, activ: Callable):
    x = F.layer_norm(x, (x.shape[-1],))
    return activ(x)


class BaseMLP(nn.Module):
    def __init__(self, input_dim: int, output_dim: int, hdim: int, activ: str = "elu"):
        super().__init__()
        self.l1 = nn.Linear(input_dim, hdim)
        self.l2 = nn.Linear(hdim, hdim)
        self.l3 = nn.Linear(hdim, output_dim)

        self.activ = getattr(F, activ)
        self.apply(weight_init)

    def forward(self, x: torch.Tensor):
        y = ln_activ(self.l1(x), self.activ)
        y = ln_activ(self.l2(y), self.activ)
        return self.l3(y)


class Encoder(nn.Module):
    def __init__(
        self,
        state_dim: int,
        action_dim: int,
        pixel_obs: bool,
        num_bins: int = 65,
        zs_dim: int = 512,
        za_dim: int = 256,
        zsa_dim: int = 512,
        hdim: int = 512,
        activ: str = "elu",
        use_last_embedding: bool = False,
        use_hf_model: bool = False,
    ):
        super().__init__()
        self.eagle_seq_len = 1 if use_last_embedding else 20
        self.eagle_hidden_dim = 896 if use_hf_model else 1536
        self.eagle_state_dim = 512
        self.robot_state_dim = 3
        if pixel_obs:
            self.zs = self.cnn_zs
            self.zs_cnn1 = nn.Conv2d(state_dim, 32, 3, stride=2)
            self.zs_cnn2 = nn.Conv2d(32, 32, 3, stride=2)
            self.zs_cnn3 = nn.Conv2d(32, 32, 3, stride=2)
            self.zs_cnn4 = nn.Conv2d(32, 32, 3, stride=1)
            self.zs_lin = nn.Linear(1568, zs_dim)
        else:
            self.zs = self.mlp_zs
            self.zs_mlp = BaseMLP(
                self.robot_state_dim + self.eagle_state_dim, zs_dim, hdim, activ
            )

        self.za = nn.Linear(action_dim, za_dim)
        self.zsa = BaseMLP(zs_dim + za_dim, zsa_dim, hdim, activ)
        self.model = nn.Linear(zsa_dim, num_bins + zs_dim + 1)
        self.linear = nn.Linear(self.eagle_hidden_dim, self.eagle_state_dim)
        self.pooler = nn.AdaptiveAvgPool1d(1)
        self.zs_dim = zs_dim

        self.activ = getattr(F, activ)
        self.apply(weight_init)

    def forward(self, zs: torch.Tensor, action: torch.Tensor):
        za = self.activ(self.za(action))
        return self.zsa(torch.cat([zs, za], 1))

    def model_all(self, zs: torch.Tensor, action: torch.Tensor):
        zsa = self.forward(zs, action)
        dzr = self.model(zsa)
        return (
            dzr[:, 0:1],
            dzr[:, 1 : self.zs_dim + 1],
            dzr[:, self.zs_dim + 1 :],
        )  # done, zs, reward

    def cnn_zs(self, state: torch.Tensor):
        state = state / 255.0 - 0.5
        zs = self.activ(self.zs_cnn1(state))
        zs = self.activ(self.zs_cnn2(zs))
        zs = self.activ(self.zs_cnn3(zs))
        zs = self.activ(self.zs_cnn4(zs)).reshape(state.shape[0], -1)
        return ln_activ(self.zs_lin(zs), self.activ)

    def mlp_zs(self, state: torch.Tensor):
        # state.shape = (B, 3+20*1536)
        # robot_state.shape = (B, 3)
        robot_state = state[:, : self.robot_state_dim]
        # task_embedding.shape = (B, 20*1536)
        task_embedding = state[:, self.robot_state_dim :]
        # task_embedding.shape(B, 20, 1536)
        task_embedding = self.linear(
            task_embedding.reshape(-1, self.eagle_seq_len, self.eagle_hidden_dim)
        )
        # task_embedding.shape(B, 20, 512) -> (B, 512, 20) -> (B, 512, 1) -> (B, 512)
        task_embedding = self.pooler(task_embedding.transpose(1, 2)).squeeze(-1)
        # combined_state.shape = (B, 3+512)
        combined_state = torch.cat([robot_state, task_embedding], dim=1)
        return ln_activ(self.zs_mlp(combined_state), self.activ)


class Policy(nn.Module):
    def __init__(
        self,
        action_dim: int,
        discrete: bool,
        gumbel_tau: float = 10,
        zs_dim: int = 512,
        hdim: int = 512,
        activ: str = "relu",
    ):
        super().__init__()
        self.policy = BaseMLP(zs_dim, action_dim, hdim, activ)
        self.activ = (
            partial(F.gumbel_softmax, tau=gumbel_tau) if discrete else torch.tanh
        )
        self.discrete = discrete

    def forward(self, zs: torch.Tensor):
        pre_activ = self.policy(zs)
        action = self.activ(pre_activ)
        return action, pre_activ

    def act(self, zs: torch.Tensor):
        action, _ = self.forward(zs)
        return action


class Value(nn.Module):
    def __init__(self, zsa_dim: int = 512, hdim: int = 512, activ: str = "elu"):
        super().__init__()

        class ValueNetwork(nn.Module):
            def __init__(
                self,
                input_dim: int,
                output_dim: int,
                hdim: int = 512,
                activ: str = "elu",
            ):
                super().__init__()
                self.q1 = BaseMLP(input_dim, hdim, hdim, activ)
                self.q2 = nn.Linear(hdim, output_dim)

                self.activ = getattr(F, activ)
                self.apply(weight_init)

            def forward(self, zsa: torch.Tensor):
                zsa = ln_activ(self.q1(zsa), self.activ)
                return self.q2(zsa)

        self.q1 = ValueNetwork(zsa_dim, 1, hdim, activ)
        self.q2 = ValueNetwork(zsa_dim, 1, hdim, activ)

    def forward(self, zsa: torch.Tensor):
        return torch.cat([self.q1(zsa), self.q2(zsa)], 1)
